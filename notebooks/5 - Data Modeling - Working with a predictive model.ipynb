{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraindo dados da Covid19 via API\n",
    "### Fonte de Dados: https://brasil.io/dataset/covid19/\n",
    "### Augusto SPINELLI\n",
    "\n",
    "### Licença\n",
    "Os dados dados convertidos estão sob a licença Creative Commons Attribution ShareAlike. Caso utilize os dados, cite a fonte original e quem tratou os dados, como: Fonte: Secretarias de Saúde das Unidades Federativas, dados tratados por Álvaro Justen e colaboradores/Brasil.IO. Caso compartilhe os dados, utilize a mesma licença."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the path of the processed data\n",
    "processed_data_path = os.path.join(os.path.pardir,'data','processed')\n",
    "train_file_path = os.path.join(processed_data_path,'train.csv')\n",
    "test_file_path = os.path.join(processed_data_path,'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train and test dataframes using pandas\n",
    "train_df = pd.read_csv(train_file_path,index_col=[0])\n",
    "test_df = pd.read_csv(test_file_path,index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 49450 entries, 0 to 50639\n",
      "Data columns (total 11 columns):\n",
      " #   Column                     Non-Null Count  Dtype\n",
      "---  ------                     --------------  -----\n",
      " 0   sobreviveu                 49450 non-null  int64\n",
      " 1   ap_residencia_estadia_1.0  49450 non-null  int64\n",
      " 2   ap_residencia_estadia_2.1  49450 non-null  int64\n",
      " 3   ap_residencia_estadia_2.2  49450 non-null  int64\n",
      " 4   ap_residencia_estadia_3.1  49450 non-null  int64\n",
      " 5   ap_residencia_estadia_3.2  49450 non-null  int64\n",
      " 6   ap_residencia_estadia_3.3  49450 non-null  int64\n",
      " 7   ap_residencia_estadia_4.0  49450 non-null  int64\n",
      " 8   ap_residencia_estadia_5.1  49450 non-null  int64\n",
      " 9   ap_residencia_estadia_5.2  49450 non-null  int64\n",
      " 10  ap_residencia_estadia_5.3  49450 non-null  int64\n",
      "dtypes: int64(11)\n",
      "memory usage: 4.5 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1190 entries, 70 to 50633\n",
      "Data columns (total 10 columns):\n",
      " #   Column                     Non-Null Count  Dtype\n",
      "---  ------                     --------------  -----\n",
      " 0   ap_residencia_estadia_1.0  1190 non-null   int64\n",
      " 1   ap_residencia_estadia_2.1  1190 non-null   int64\n",
      " 2   ap_residencia_estadia_2.2  1190 non-null   int64\n",
      " 3   ap_residencia_estadia_3.1  1190 non-null   int64\n",
      " 4   ap_residencia_estadia_3.2  1190 non-null   int64\n",
      " 5   ap_residencia_estadia_3.3  1190 non-null   int64\n",
      " 6   ap_residencia_estadia_4.0  1190 non-null   int64\n",
      " 7   ap_residencia_estadia_5.1  1190 non-null   int64\n",
      " 8   ap_residencia_estadia_5.2  1190 non-null   int64\n",
      " 9   ap_residencia_estadia_5.3  1190 non-null   int64\n",
      "dtypes: int64(10)\n",
      "memory usage: 102.3 KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Vamos agora pegar nossos dados de training e quebrá-lo de forma a ter 80% en uma matrix e 20% em outro.\n",
    "\n",
    "No final, vamos comparar a taxa de sobrevivência em ambos splits para ver se são similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.loc[:,'ap_residencia_estadia_1.0':].to_numpy().astype('float') #input matrix\n",
    "y = train_df['sobreviveu'].ravel() #output array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49450, 10) (49450,)\n"
     ]
    }
   ],
   "source": [
    "print (X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39560, 10) (39560,)\n",
      "(9890, 10) (9890,)\n"
     ]
    }
   ],
   "source": [
    "#ML train test split 80/20 (80% will be used to train, 20% to test)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean survival in train: 0.905\n",
      "mean survival in test: 0.903\n"
     ]
    }
   ],
   "source": [
    "#average survival in train and test, without ML \n",
    "print('mean survival in train: {0:.3f}'.format(np.mean(y_train)))\n",
    "print('mean survival in test: {0:.3f}'.format(np.mean(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Base (Baseline Model)\n",
    "\n",
    "Este modelo é o nosso modelo base. É o mais burro possível e sempre considera que o paciente sobreviverá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "#import function\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a model\n",
    "model_dummy = DummyClassifier(strategy='most_frequent',random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=0, strategy='most_frequent')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train a model\n",
    "model_dummy.fit(X_train,y_train) #input,output params are necessary for fit training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for baseline model : 0.90\n"
     ]
    }
   ],
   "source": [
    "#calculate model score (baseline considers most frequent data, a.k.a 1 ==  survived covid)\n",
    "print('score for baseline model : {0:.2f}'.format(model_dummy.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So, without any ML algorithm, if we simply predict that a pacient with covid survives, we will be right in 90% of the cases\n",
    "#let's try to improve that with ML! \n",
    "#First, lets import some performance metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for baseline model : 0.90\n",
      "confusion matrix for baseline model : \n",
      " [[   0  959]\n",
      " [   0 8931]]\n",
      "precision for baseline model : 0.90\n",
      "recall for baseline model : 1.00\n"
     ]
    }
   ],
   "source": [
    "#accuracy score\n",
    "print('accuracy for baseline model : {0:.2f}'.format(accuracy_score(y_test,model_dummy.predict(X_test))))\n",
    "#confusion matrix\n",
    "print('confusion matrix for baseline model : \\n {0}'.format(confusion_matrix(y_test,model_dummy.predict(X_test))))\n",
    "#precision and recall scores\n",
    "print('precision for baseline model : {0:.2f}'.format(precision_score(y_test,model_dummy.predict(X_test))))\n",
    "print('recall for baseline model : {0:.2f}'.format(recall_score(y_test,model_dummy.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de regressão lógica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import logistic regression function from sklearn\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create our model \n",
    "model_lr_1 = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train our model\n",
    "model_lr_1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for logistic regression - version 1 : 0.90\n"
     ]
    }
   ],
   "source": [
    "#evaluate model\n",
    "print('score for logistic regression - version 1 : {0:.2f}'.format(model_lr_1.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for logistic regression v1 model : 0.90\n",
      "confusion matrix for logistic regression v1 model : \n",
      " [[   0  959]\n",
      " [   0 8931]]\n",
      "precision for logistic regression v1 model : 0.90\n",
      "recall for logistic regression v1 model : 1.00\n"
     ]
    }
   ],
   "source": [
    "#performance metrics\n",
    "\n",
    "#accuracy score\n",
    "print('accuracy for logistic regression v1 model : {0:.2f}'.format(accuracy_score(y_test,model_lr_1.predict(X_test))))\n",
    "#confusion matrix\n",
    "print('confusion matrix for logistic regression v1 model : \\n {0}'.format(confusion_matrix(y_test,model_lr_1.predict(X_test))))\n",
    "#precision \n",
    "print('precision for logistic regression v1 model : {0:.2f}'.format(precision_score(y_test,model_lr_1.predict(X_test))))\n",
    "#recall\n",
    "print('recall for logistic regression v1 model : {0:.2f}'.format(recall_score(y_test,model_lr_1.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimização de hyperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base model\n",
    "model_lr = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C':[1.0,10.0,50.0,100.0,1000.0],'penalty':['l1','l2']}\n",
    "clf = GridSearchCV(model_lr,param_grid=parameters,cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gutospinelli/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/gutospinelli/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/gutospinelli/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/gutospinelli/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/gutospinelli/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=0, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [1.0, 10.0, 50.0, 100.0, 1000.0],\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.90\n"
     ]
    }
   ],
   "source": [
    "print('best score: {0:.2f}'.format(clf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for logistic regression v2 : 0.90\n"
     ]
    }
   ],
   "source": [
    "#evaluate model\n",
    "print('score for logistic regression v2 : {0:.2f}'.format(clf.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Notebook\n",
    "\n",
    "#### Não estamos melhorando nosso modelo base. Como dispomos de dados pobres nesse exemplo e o modelo base já tem fidelidade de 90% (a maioria dos pacientes de covid sobrevivem), um modelo que usa regressão lógica não é suficiente para prever com uma fidelidade ainda maior (dados os poucos parâmetros disponíveis) se o paciente irá sobreviver ou não\n",
    "\n",
    "#### Neste caso, voltamos a prancheta. Precisamos ter ainda mais dados disponíveis como sexo, idade, renda, etc (e não somente ap de residencia) para tentar montar um modelo mais fiel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
